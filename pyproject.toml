[project]
name = "kv-cache-optimizer"
version = "0.1.0"
description = "Efficient Prefill: Blocked Quantization for Batched LLM Inference"
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.10"
authors = [
    {name = "X"},
]
dependencies = [
    "torch==2.4.0",
    "transformers>=4.40.0",
    "pynvml>=11.5.0",
    "codecarbon>=2.3.0",
    "wandb>=0.16.0",
    "scipy>=1.11.0",
    "matplotlib>=3.7.0",
    "numpy>=1.24.0",
    "datasets>=2.18.0",
    "accelerate>=0.28.0",
    "sentencepiece>=0.2.0",
    "protobuf>=4.25.0",
]

[dependency-groups]
dev = [
    "ruff>=0.4.0",
    "pytest>=8.0.0",
    "pytest-cov>=5.0.0",
    "mypy>=1.9.0",
    "pre-commit>=3.7.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = [
    "E", "W",   # pycodestyle
    "F",         # Pyflakes
    "I",         # isort
    "UP",        # pyupgrade
    "B",         # flake8-bugbear
    "SIM",       # flake8-simplify
    "RUF",       # Ruff-specific rules
]
ignore = ["E501"]  # line length handled by formatter

[tool.ruff.lint.isort]
known-first-party = ["kvquant", "utils"]

[tool.pytest.ini_options]
testpaths = ["tests"]
markers = [
    "gpu: marks tests that require CUDA GPU (deselect with '-m \"not gpu\"')",
]
